{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('PythonData': conda)",
   "display_name": "Python 3.7.7 64-bit ('PythonData': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8eb93c95bd66bb1c37e84a7a0539426e5182ed0a06a9d52f414e0eeb4198a997"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import our input dataset\n",
    "diabetes_df = pd.read_csv('diabetes.csv')\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove diabetes outcome target from features data\n",
    "y = diabetes_df.Outcome\n",
    "X = diabetes_df.drop(columns=\"Outcome\")\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess numerical data for neural network\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " Logistic regression model accuracy: 0.729\n"
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "log_classifier = LogisticRegression(solver=\"lbfgs\",max_iter=200)\n",
    "\n",
    "# Train the model\n",
    "log_classifier.fit(X_train,y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = log_classifier.predict(X_test)\n",
    "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n576/576 [==============================] - 0s 329us/sample - loss: 0.7404 - acc: 0.5174\nEpoch 2/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.7052 - acc: 0.5833\nEpoch 3/100\n576/576 [==============================] - 0s 54us/sample - loss: 0.6753 - acc: 0.6215\nEpoch 4/100\n576/576 [==============================] - 0s 62us/sample - loss: 0.6503 - acc: 0.6441\nEpoch 5/100\n576/576 [==============================] - 0s 47us/sample - loss: 0.6283 - acc: 0.6753\nEpoch 6/100\n576/576 [==============================] - 0s 47us/sample - loss: 0.6098 - acc: 0.6944\nEpoch 7/100\n576/576 [==============================] - 0s 38us/sample - loss: 0.5935 - acc: 0.7101\nEpoch 8/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.5788 - acc: 0.7153\nEpoch 9/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.5662 - acc: 0.7292\nEpoch 10/100\n576/576 [==============================] - 0s 52us/sample - loss: 0.5542 - acc: 0.7326\nEpoch 11/100\n576/576 [==============================] - 0s 59us/sample - loss: 0.5443 - acc: 0.7396\nEpoch 12/100\n576/576 [==============================] - 0s 61us/sample - loss: 0.5357 - acc: 0.7448\nEpoch 13/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.5275 - acc: 0.7500\nEpoch 14/100\n576/576 [==============================] - 0s 43us/sample - loss: 0.5207 - acc: 0.7552\nEpoch 15/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.5140 - acc: 0.7587\nEpoch 16/100\n576/576 [==============================] - 0s 43us/sample - loss: 0.5087 - acc: 0.7569\nEpoch 17/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.5038 - acc: 0.7569\nEpoch 18/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.4997 - acc: 0.7604\nEpoch 19/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4952 - acc: 0.7622\nEpoch 20/100\n576/576 [==============================] - 0s 47us/sample - loss: 0.4918 - acc: 0.7656\nEpoch 21/100\n576/576 [==============================] - 0s 47us/sample - loss: 0.4885 - acc: 0.7708\nEpoch 22/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4856 - acc: 0.7726\nEpoch 23/100\n576/576 [==============================] - 0s 38us/sample - loss: 0.4830 - acc: 0.7795\nEpoch 24/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4805 - acc: 0.7795\nEpoch 25/100\n576/576 [==============================] - 0s 43us/sample - loss: 0.4783 - acc: 0.7760\nEpoch 26/100\n576/576 [==============================] - 0s 47us/sample - loss: 0.4761 - acc: 0.7778\nEpoch 27/100\n576/576 [==============================] - 0s 47us/sample - loss: 0.4739 - acc: 0.7795\nEpoch 28/100\n576/576 [==============================] - 0s 43us/sample - loss: 0.4720 - acc: 0.7847\nEpoch 29/100\n576/576 [==============================] - 0s 50us/sample - loss: 0.4705 - acc: 0.7882\nEpoch 30/100\n576/576 [==============================] - 0s 50us/sample - loss: 0.4686 - acc: 0.7917\nEpoch 31/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.4672 - acc: 0.7934\nEpoch 32/100\n576/576 [==============================] - 0s 38us/sample - loss: 0.4656 - acc: 0.7951\nEpoch 33/100\n576/576 [==============================] - 0s 40us/sample - loss: 0.4642 - acc: 0.7951\nEpoch 34/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.4628 - acc: 0.7986\nEpoch 35/100\n576/576 [==============================] - 0s 52us/sample - loss: 0.4617 - acc: 0.7986\nEpoch 36/100\n576/576 [==============================] - 0s 40us/sample - loss: 0.4605 - acc: 0.7951\nEpoch 37/100\n576/576 [==============================] - 0s 59us/sample - loss: 0.4591 - acc: 0.7969\nEpoch 38/100\n576/576 [==============================] - 0s 43us/sample - loss: 0.4581 - acc: 0.7969\nEpoch 39/100\n576/576 [==============================] - 0s 40us/sample - loss: 0.4570 - acc: 0.7969\nEpoch 40/100\n576/576 [==============================] - 0s 50us/sample - loss: 0.4567 - acc: 0.7969\nEpoch 41/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.4552 - acc: 0.7951\nEpoch 42/100\n576/576 [==============================] - 0s 40us/sample - loss: 0.4540 - acc: 0.7969\nEpoch 43/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4534 - acc: 0.7969\nEpoch 44/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.4523 - acc: 0.7986\nEpoch 45/100\n576/576 [==============================] - 0s 52us/sample - loss: 0.4516 - acc: 0.7986\nEpoch 46/100\n576/576 [==============================] - 0s 43us/sample - loss: 0.4508 - acc: 0.7986\nEpoch 47/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.4499 - acc: 0.7986\nEpoch 48/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4492 - acc: 0.8021\nEpoch 49/100\n576/576 [==============================] - 0s 52us/sample - loss: 0.4482 - acc: 0.8021\nEpoch 50/100\n576/576 [==============================] - 0s 59us/sample - loss: 0.4477 - acc: 0.8021\nEpoch 51/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4468 - acc: 0.8021\nEpoch 52/100\n576/576 [==============================] - 0s 54us/sample - loss: 0.4460 - acc: 0.8021\nEpoch 53/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.4454 - acc: 0.7986\nEpoch 54/100\n576/576 [==============================] - 0s 52us/sample - loss: 0.4449 - acc: 0.7969\nEpoch 55/100\n576/576 [==============================] - 0s 55us/sample - loss: 0.4439 - acc: 0.7951\nEpoch 56/100\n576/576 [==============================] - 0s 54us/sample - loss: 0.4432 - acc: 0.7969\nEpoch 57/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.4433 - acc: 0.7986\nEpoch 58/100\n576/576 [==============================] - 0s 57us/sample - loss: 0.4425 - acc: 0.7969\nEpoch 59/100\n576/576 [==============================] - 0s 43us/sample - loss: 0.4418 - acc: 0.7969\nEpoch 60/100\n576/576 [==============================] - 0s 40us/sample - loss: 0.4409 - acc: 0.7986\nEpoch 61/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4407 - acc: 0.7986\nEpoch 62/100\n576/576 [==============================] - 0s 50us/sample - loss: 0.4399 - acc: 0.7986\nEpoch 63/100\n576/576 [==============================] - 0s 64us/sample - loss: 0.4396 - acc: 0.7986\nEpoch 64/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.4389 - acc: 0.7986\nEpoch 65/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4383 - acc: 0.7969\nEpoch 66/100\n576/576 [==============================] - 0s 50us/sample - loss: 0.4381 - acc: 0.7969\nEpoch 67/100\n576/576 [==============================] - 0s 47us/sample - loss: 0.4374 - acc: 0.7969\nEpoch 68/100\n576/576 [==============================] - 0s 50us/sample - loss: 0.4377 - acc: 0.7986\nEpoch 69/100\n576/576 [==============================] - 0s 47us/sample - loss: 0.4366 - acc: 0.7986\nEpoch 70/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.4360 - acc: 0.7986\nEpoch 71/100\n576/576 [==============================] - 0s 40us/sample - loss: 0.4357 - acc: 0.7986\nEpoch 72/100\n576/576 [==============================] - 0s 55us/sample - loss: 0.4353 - acc: 0.7986\nEpoch 73/100\n576/576 [==============================] - 0s 59us/sample - loss: 0.4346 - acc: 0.7969\nEpoch 74/100\n576/576 [==============================] - 0s 128us/sample - loss: 0.4343 - acc: 0.7986\nEpoch 75/100\n576/576 [==============================] - 0s 66us/sample - loss: 0.4339 - acc: 0.7986\nEpoch 76/100\n576/576 [==============================] - 0s 71us/sample - loss: 0.4339 - acc: 0.8003\nEpoch 77/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4327 - acc: 0.7986\nEpoch 78/100\n576/576 [==============================] - 0s 55us/sample - loss: 0.4325 - acc: 0.7969\nEpoch 79/100\n576/576 [==============================] - 0s 43us/sample - loss: 0.4319 - acc: 0.7969\nEpoch 80/100\n576/576 [==============================] - 0s 38us/sample - loss: 0.4317 - acc: 0.7969\nEpoch 81/100\n576/576 [==============================] - 0s 38us/sample - loss: 0.4310 - acc: 0.7969\nEpoch 82/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.4306 - acc: 0.7986\nEpoch 83/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4304 - acc: 0.7986\nEpoch 84/100\n576/576 [==============================] - 0s 55us/sample - loss: 0.4298 - acc: 0.8003\nEpoch 85/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.4295 - acc: 0.7986\nEpoch 86/100\n576/576 [==============================] - 0s 50us/sample - loss: 0.4290 - acc: 0.8003\nEpoch 87/100\n576/576 [==============================] - 0s 55us/sample - loss: 0.4286 - acc: 0.8003\nEpoch 88/100\n576/576 [==============================] - 0s 54us/sample - loss: 0.4283 - acc: 0.8021\nEpoch 89/100\n576/576 [==============================] - 0s 42us/sample - loss: 0.4277 - acc: 0.8021\nEpoch 90/100\n576/576 [==============================] - 0s 64us/sample - loss: 0.4274 - acc: 0.8003\nEpoch 91/100\n576/576 [==============================] - 0s 54us/sample - loss: 0.4270 - acc: 0.8003\nEpoch 92/100\n576/576 [==============================] - 0s 88us/sample - loss: 0.4266 - acc: 0.8003\nEpoch 93/100\n576/576 [==============================] - 0s 135us/sample - loss: 0.4266 - acc: 0.7986\nEpoch 94/100\n576/576 [==============================] - 0s 59us/sample - loss: 0.4260 - acc: 0.7986\nEpoch 95/100\n576/576 [==============================] - 0s 62us/sample - loss: 0.4254 - acc: 0.8021\nEpoch 96/100\n576/576 [==============================] - 0s 48us/sample - loss: 0.4253 - acc: 0.8038\nEpoch 97/100\n576/576 [==============================] - 0s 40us/sample - loss: 0.4247 - acc: 0.8073\nEpoch 98/100\n576/576 [==============================] - 0s 52us/sample - loss: 0.4243 - acc: 0.8056\nEpoch 99/100\n576/576 [==============================] - 0s 45us/sample - loss: 0.4241 - acc: 0.8056\nEpoch 100/100\n576/576 [==============================] - 0s 62us/sample - loss: 0.4238 - acc: 0.8038\n192/192 - 0s - loss: 0.4830 - acc: 0.7344\nLoss: 0.48296838998794556, Accuracy: 0.734375\n"
    }
   ],
   "source": [
    "# Define the basic neural network model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\", input_dim=8))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}